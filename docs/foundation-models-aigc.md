# 大模型

## 课程简介

AI 大模型的出现为通用人工智能时代开启了一个新纪元，作为一种颠覆性的技术象征，正在重新定义我们的工作方式和创新边界。本课程将致力于解答 AIGC 和大模型应用开发中的会遇到的关键问题，帮助学员掌握这项重要技术带来的生产力红利。这些关键问题将包括：

1. AI 大模型的原理是什么？
2. 现阶段 AI 大模型的能力边界在哪里？
3. 使用 AI 大模型的能力基础？
4. 非 IT 人士如何在日常中充分挖掘 AI 大模型能力以提升工作效率与质量？
5. IT 研发人员如何使用 AI 大模型实现业务场景应用落地？
6. AI 大模型的工程化范式有哪些？
7. AI 大模型工程范式的优势与局限又分别在哪里？

等等

## 课程内容

1. 技术原理与演化路径

    包括 AI 大模型发展与演化的前世今生、Self-Attention 机制、Transformer 的三种架构演化等技术原理，以及在学术、工程、社会科学等领域的最新应用案例。帮助学员掌握 AI 大模型内在运作方式及其能力边界、能力发展趋势。

2. Prompt Engineering

    这是与 AI 大模型互动的核心技能，适合所有专业与非专业人士，不受限于技术门槛，通过自然语言及简单的逻辑框架构建问题和指令，与AI大模型进行更有效的互动，以获得最精确的答案和结果。

3. AI 大模型的工程化范式

    这一部分将帮助学员将 AI 大模型落地具体应用需求场景的工程实践。了解如何使用 Vector DB、Langchain 等工具实现 CVP 开发，如何设计和开发 Agent 全过程，掌握以 Agent 为核心的工具链能力。

4. Fine-Tuning

    使用新的数据集对预训练模型的参数进行微调，使模型在特定任务中表现出更好的准确性和泛化能力。包括调整模型的权重、增加或删除层、调整层的参数等。

## 1. LLM 初探

### 1.1 现象级的 ChatGPT

### 1.2 LLM 的爆发路径及智慧化演进

### 1.3 LLM 的能力、局限、优与劣

## 2. LLM 技术原理

### 2.1 自然语言处理发展历史

### 2.2 关键技术 Self-Attention

### 2.3 Transformer 的三种架构演化

### 2.4 预训练（Pre-training）

### 2.5 微调（Fine-Tuning）

### 2.6 提示（Prompt）

## 3. 演进路径

### 3.1 ChatGPT 的技术演化

### 3.2 Data-centric AI

### 3.3 情境学习（In Context Learning)

### 3.4 代码训练数据

### 3.5 开源 LLM

#### 3.5.1 LLaMA家族

#### 3.5.2 开源中文预训练模型

### 3.6 大模型的衍进思路和未来方向分析

## 4. Prompt Engineering 和应用实践

### 4.1 提示工程介绍

### 4.2 提示构建基本原则

### 4.3 提示工程构建

#### 4.3.1 输入检查

#### 4.3.2 思维链推理

#### 4.3.3 评估

### 4.4 提示工程高级技巧

#### 4.4.1 上下文学习 In-context Learning

#### 4.4.2 思维链Chain of Thought

#### 4.4.3 Prompt 模板 Template

#### 4.4.4 Prompt 集成 Ensembling

#### 4.4.5 自我一致性 Self-consistency

#### 4.4.6 对抗性提示 Adversarial Prompting

#### 4.4.7 可靠性 Reliability

#### 4.4.8 自动 Prompt 工程 Automatic Prompt Engineer

## 5. 大模型向量工程和 CVP 范式

### 5.1 大模型中的向量工程

#### 5.1.1 向量工程介绍

#### 5.1.2 为什么要使用向量工程

### 5.2 大模型应用新范式 CVP 介绍

#### 5.2.1 CVP 是什么

#### 5.2.2 CVP 的意义

#### 5.2.3 详解 CVP 开发

### 5.3 向量数据库介绍和实践

#### 5.3.1 milvus 安装

#### 5.3.2 milvus 实战

#### 5.3.3 milvus 原理

#### 5.3.4 其他向量数据库介绍

## 6. 大模型开发新范式：LangChain

### 6.1 Langchain 简介

### 6.2 模型、提示和解析器

### 6.3 零微调范式 ReAct & Self Ask

### 6.4 记忆扩展

### 6.5 Chian

### 6.6 AI Agent

### 6.7 Langchain实训

#### 6.7.1

#### 6.7.2

#### 6.7.3

### 6.8 基于 Langchain 机器人的评估

## 7. 增强大模型能力

### 7.1 Llama-index 增强数据能力

#### 7.1.1 Llama-index 介绍

#### 7.1.2 Llama-index 原理

#### 7.1.3 使用 Llama-index 增强应用

### 7.2 知识图谱对于机器人的增强

#### 7.2.1 知识图谱技术基础

#### 7.2.2 知识图谱应用技术

### 7.3 增强机器人任务拆分推理能力

## 8. 人工反馈强化学习 (RLHF) 指导模型对齐

### 8.1 什么是强化学习

### 8.2 强化学习的基础概念

### 8.3 为什么需要 RLHF?

### 8.4 RLHF 训练过程

### 8.5 数据标注和奖励模型训练

### 8.6 RLHF 训练实训

#### 8.6.1

#### 8.6.2

## 9. 大模型训练框架

### 9.1 NVAIE【此处结合一体机】

### 9.2

## 10. Fine-tuning

### 10.1 Transformer 深度解析

### 10.2 模型训练 Pipeline

### 10.3 Huggingface 框架介绍

### 10.4 模型微调 (Fine-Tuning)

### 10.5 小参数量模型微调 (PEFT)

### 10.6 Fine-tuning 的适用性与局限性

### 10.7 基于 ChatGLM的Fine-tuning

#### 10.7.1 环境搭建

#### 10.7.2 全量参数 Fine-tuning

#### 10.7.3 小参数量微调之 P-Tuning V2

#### 10.7.4 小参数量微调之 LORA

### 10.8 训练数据集预处理技巧

## 11. 大模型评估流程、方法和注意事项
